{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras Perceptron on Indian Liver Patient.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN+uVwXEK4Xe3c+3EIsmWQD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aiswaryadevi/AI-deeplearning/blob/master/Keras_Perceptron_on_Indian_Liver_Patient.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQfCJDOSksdK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b805e023-5c9b-4f4e-9b21-26214fb075bd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_45X6Ctksee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg1PAzqpksiw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('indian_liver_patient.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDRfMK_Fksou",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "2f005286-1970-4856-eb01-ccf2b699f81a"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 583 entries, 0 to 582\n",
            "Data columns (total 11 columns):\n",
            "Age                           583 non-null int64\n",
            "Gender                        583 non-null object\n",
            "Total_Bilirubin               583 non-null float64\n",
            "Direct_Bilirubin              583 non-null float64\n",
            "Alkaline_Phosphotase          583 non-null int64\n",
            "Alamine_Aminotransferase      583 non-null int64\n",
            "Aspartate_Aminotransferase    583 non-null int64\n",
            "Total_Protiens                583 non-null float64\n",
            "Albumin                       583 non-null float64\n",
            "Albumin_and_Globulin_Ratio    579 non-null float64\n",
            "Dataset                       583 non-null int64\n",
            "dtypes: float64(5), int64(5), object(1)\n",
            "memory usage: 50.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grMAfu9bkst7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "0d77f23f-b2a5-4016-8c0b-67a839861bf6"
      },
      "source": [
        "\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(data['Gender'])\n",
        "data['Gender']=le.transform(data['Gender'])\n",
        "data.dropna(inplace=True)\n",
        "data['Albumin_and_Globulin_Ratio'] = data['Albumin_and_Globulin_Ratio'].dropna()\n",
        "data.info()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 579 entries, 0 to 582\n",
            "Data columns (total 11 columns):\n",
            "Age                           579 non-null int64\n",
            "Gender                        579 non-null int64\n",
            "Total_Bilirubin               579 non-null float64\n",
            "Direct_Bilirubin              579 non-null float64\n",
            "Alkaline_Phosphotase          579 non-null int64\n",
            "Alamine_Aminotransferase      579 non-null int64\n",
            "Aspartate_Aminotransferase    579 non-null int64\n",
            "Total_Protiens                579 non-null float64\n",
            "Albumin                       579 non-null float64\n",
            "Albumin_and_Globulin_Ratio    579 non-null float64\n",
            "Dataset                       579 non-null int64\n",
            "dtypes: float64(5), int64(6)\n",
            "memory usage: 54.3 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeXMY2Xvkszh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=data['Dataset']\n",
        "data.drop(['Dataset'],axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilgOk-rPks4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.275, stratify=y,random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rY_fp84olH2q",
        "colab_type": "text"
      },
      "source": [
        "# **KERAS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt7Iu6-vks93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.compat.v1 as tf \n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0Hx4MDVktDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.set_random_seed(42) \n",
        "np.random.seed(42)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wicsupxoktH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeABILe0ktNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "sc.fit(X_train)\n",
        "X_train_std = sc.transform(X_train) \n",
        "X_test_std = sc.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMEBe-TAktR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_perceptron = keras.models.Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJm42t7RktMQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "66a4da0a-c1a1-4f3b-f806-b30eabbc99d4"
      },
      "source": [
        "\n",
        "model_perceptron.add(keras.layers.Dense(units=1, activation='relu',input_shape= X_train.shape[1:]))\n",
        "model_perceptron.add(keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtxBkY3vktHL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5f04ac0f-769c-4a86-9147-06e123a86b8e"
      },
      "source": [
        "\n",
        "model_perceptron.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "model_perceptron.fit(x=X_train_std, y=y_train, validation_split=0.1,epochs=50, batch_size=16)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 377 samples, validate on 42 samples\n",
            "Epoch 1/50\n",
            "377/377 [==============================] - 0s 769us/sample - loss: 0.6191 - acc: 0.6870 - val_loss: 0.6327 - val_acc: 0.8333\n",
            "Epoch 2/50\n",
            "377/377 [==============================] - 0s 84us/sample - loss: 0.5842 - acc: 0.7029 - val_loss: 0.6056 - val_acc: 0.8333\n",
            "Epoch 3/50\n",
            "377/377 [==============================] - 0s 86us/sample - loss: 0.5478 - acc: 0.7029 - val_loss: 0.5779 - val_acc: 0.8333\n",
            "Epoch 4/50\n",
            "377/377 [==============================] - 0s 84us/sample - loss: 0.5101 - acc: 0.7029 - val_loss: 0.5498 - val_acc: 0.8333\n",
            "Epoch 5/50\n",
            "377/377 [==============================] - 0s 84us/sample - loss: 0.4717 - acc: 0.7029 - val_loss: 0.5200 - val_acc: 0.8333\n",
            "Epoch 6/50\n",
            "377/377 [==============================] - 0s 100us/sample - loss: 0.4313 - acc: 0.7029 - val_loss: 0.4897 - val_acc: 0.8333\n",
            "Epoch 7/50\n",
            "377/377 [==============================] - 0s 88us/sample - loss: 0.3896 - acc: 0.7029 - val_loss: 0.4588 - val_acc: 0.8333\n",
            "Epoch 8/50\n",
            "377/377 [==============================] - 0s 83us/sample - loss: 0.3464 - acc: 0.7029 - val_loss: 0.4269 - val_acc: 0.8333\n",
            "Epoch 9/50\n",
            "377/377 [==============================] - 0s 89us/sample - loss: 0.3021 - acc: 0.7029 - val_loss: 0.3928 - val_acc: 0.8333\n",
            "Epoch 10/50\n",
            "377/377 [==============================] - 0s 91us/sample - loss: 0.2560 - acc: 0.7029 - val_loss: 0.3585 - val_acc: 0.8333\n",
            "Epoch 11/50\n",
            "377/377 [==============================] - 0s 81us/sample - loss: 0.2096 - acc: 0.7029 - val_loss: 0.3227 - val_acc: 0.8333\n",
            "Epoch 12/50\n",
            "377/377 [==============================] - 0s 86us/sample - loss: 0.1608 - acc: 0.7029 - val_loss: 0.2869 - val_acc: 0.8333\n",
            "Epoch 13/50\n",
            "377/377 [==============================] - 0s 88us/sample - loss: 0.1126 - acc: 0.7029 - val_loss: 0.2498 - val_acc: 0.8333\n",
            "Epoch 14/50\n",
            "377/377 [==============================] - 0s 89us/sample - loss: 0.0626 - acc: 0.7029 - val_loss: 0.2128 - val_acc: 0.8333\n",
            "Epoch 15/50\n",
            "377/377 [==============================] - 0s 82us/sample - loss: 0.0119 - acc: 0.7029 - val_loss: 0.1761 - val_acc: 0.8333\n",
            "Epoch 16/50\n",
            "377/377 [==============================] - 0s 89us/sample - loss: -0.0388 - acc: 0.7029 - val_loss: 0.1384 - val_acc: 0.8333\n",
            "Epoch 17/50\n",
            "377/377 [==============================] - 0s 91us/sample - loss: -0.0913 - acc: 0.7029 - val_loss: 0.1020 - val_acc: 0.8333\n",
            "Epoch 18/50\n",
            "377/377 [==============================] - 0s 87us/sample - loss: -0.1433 - acc: 0.7029 - val_loss: 0.0651 - val_acc: 0.8333\n",
            "Epoch 19/50\n",
            "377/377 [==============================] - 0s 88us/sample - loss: -0.1962 - acc: 0.7029 - val_loss: 0.0280 - val_acc: 0.8333\n",
            "Epoch 20/50\n",
            "377/377 [==============================] - 0s 96us/sample - loss: -0.2508 - acc: 0.7029 - val_loss: -0.0079 - val_acc: 0.8333\n",
            "Epoch 21/50\n",
            "377/377 [==============================] - 0s 92us/sample - loss: -0.3039 - acc: 0.7029 - val_loss: -0.0461 - val_acc: 0.8333\n",
            "Epoch 22/50\n",
            "377/377 [==============================] - 0s 90us/sample - loss: -0.3589 - acc: 0.7029 - val_loss: -0.0837 - val_acc: 0.8333\n",
            "Epoch 23/50\n",
            "377/377 [==============================] - 0s 86us/sample - loss: -0.4133 - acc: 0.7029 - val_loss: -0.1214 - val_acc: 0.8333\n",
            "Epoch 24/50\n",
            "377/377 [==============================] - 0s 83us/sample - loss: -0.4685 - acc: 0.7029 - val_loss: -0.1590 - val_acc: 0.8333\n",
            "Epoch 25/50\n",
            "377/377 [==============================] - 0s 87us/sample - loss: -0.5244 - acc: 0.7029 - val_loss: -0.1976 - val_acc: 0.8333\n",
            "Epoch 26/50\n",
            "377/377 [==============================] - 0s 103us/sample - loss: -0.5810 - acc: 0.7029 - val_loss: -0.2356 - val_acc: 0.8333\n",
            "Epoch 27/50\n",
            "377/377 [==============================] - 0s 86us/sample - loss: -0.6392 - acc: 0.7029 - val_loss: -0.2740 - val_acc: 0.8333\n",
            "Epoch 28/50\n",
            "377/377 [==============================] - 0s 86us/sample - loss: -0.6961 - acc: 0.7029 - val_loss: -0.3151 - val_acc: 0.8333\n",
            "Epoch 29/50\n",
            "377/377 [==============================] - 0s 85us/sample - loss: -0.7580 - acc: 0.7029 - val_loss: -0.3527 - val_acc: 0.8333\n",
            "Epoch 30/50\n",
            "377/377 [==============================] - 0s 90us/sample - loss: -0.8172 - acc: 0.7029 - val_loss: -0.3946 - val_acc: 0.8333\n",
            "Epoch 31/50\n",
            "377/377 [==============================] - 0s 97us/sample - loss: -0.8790 - acc: 0.7029 - val_loss: -0.4357 - val_acc: 0.8333\n",
            "Epoch 32/50\n",
            "377/377 [==============================] - 0s 88us/sample - loss: -0.9409 - acc: 0.7029 - val_loss: -0.4758 - val_acc: 0.8333\n",
            "Epoch 33/50\n",
            "377/377 [==============================] - 0s 94us/sample - loss: -1.0036 - acc: 0.7029 - val_loss: -0.5174 - val_acc: 0.8333\n",
            "Epoch 34/50\n",
            "377/377 [==============================] - 0s 93us/sample - loss: -1.0662 - acc: 0.7029 - val_loss: -0.5597 - val_acc: 0.8333\n",
            "Epoch 35/50\n",
            "377/377 [==============================] - 0s 93us/sample - loss: -1.1328 - acc: 0.7029 - val_loss: -0.6005 - val_acc: 0.8333\n",
            "Epoch 36/50\n",
            "377/377 [==============================] - 0s 87us/sample - loss: -1.1984 - acc: 0.7029 - val_loss: -0.6449 - val_acc: 0.8333\n",
            "Epoch 37/50\n",
            "377/377 [==============================] - 0s 88us/sample - loss: -1.2658 - acc: 0.7029 - val_loss: -0.6918 - val_acc: 0.8333\n",
            "Epoch 38/50\n",
            "377/377 [==============================] - 0s 78us/sample - loss: -1.3384 - acc: 0.7029 - val_loss: -0.7373 - val_acc: 0.8333\n",
            "Epoch 39/50\n",
            "377/377 [==============================] - 0s 79us/sample - loss: -1.4090 - acc: 0.7029 - val_loss: -0.7836 - val_acc: 0.8333\n",
            "Epoch 40/50\n",
            "377/377 [==============================] - 0s 84us/sample - loss: -1.4814 - acc: 0.7029 - val_loss: -0.8308 - val_acc: 0.8333\n",
            "Epoch 41/50\n",
            "377/377 [==============================] - 0s 83us/sample - loss: -1.5569 - acc: 0.7029 - val_loss: -0.8770 - val_acc: 0.8333\n",
            "Epoch 42/50\n",
            "377/377 [==============================] - 0s 85us/sample - loss: -1.6310 - acc: 0.7029 - val_loss: -0.9267 - val_acc: 0.8333\n",
            "Epoch 43/50\n",
            "377/377 [==============================] - 0s 86us/sample - loss: -1.7094 - acc: 0.7029 - val_loss: -0.9781 - val_acc: 0.8333\n",
            "Epoch 44/50\n",
            "377/377 [==============================] - 0s 86us/sample - loss: -1.7896 - acc: 0.7029 - val_loss: -1.0309 - val_acc: 0.8333\n",
            "Epoch 45/50\n",
            "377/377 [==============================] - 0s 88us/sample - loss: -1.8732 - acc: 0.7029 - val_loss: -1.0812 - val_acc: 0.8333\n",
            "Epoch 46/50\n",
            "377/377 [==============================] - 0s 81us/sample - loss: -1.9558 - acc: 0.7029 - val_loss: -1.1351 - val_acc: 0.8333\n",
            "Epoch 47/50\n",
            "377/377 [==============================] - 0s 78us/sample - loss: -2.0411 - acc: 0.7029 - val_loss: -1.1911 - val_acc: 0.8333\n",
            "Epoch 48/50\n",
            "377/377 [==============================] - 0s 90us/sample - loss: -2.1296 - acc: 0.7029 - val_loss: -1.2473 - val_acc: 0.8333\n",
            "Epoch 49/50\n",
            "377/377 [==============================] - 0s 81us/sample - loss: -2.2192 - acc: 0.7029 - val_loss: -1.3024 - val_acc: 0.8333\n",
            "Epoch 50/50\n",
            "377/377 [==============================] - 0s 87us/sample - loss: -2.3083 - acc: 0.7029 - val_loss: -1.3596 - val_acc: 0.8333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd9b13e4470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlHCXWW2lgwd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "98082f6a-e0cd-47e6-da45-ca99ee9166ab"
      },
      "source": [
        "test_loss, test_accuracy = model_perceptron.evaluate(x=X_test_std, y=y_test)\n",
        "print(test_loss, '\\n',test_accuracy)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "160/160 [==============================] - 0s 94us/sample - loss: -2.3556 - acc: 0.7125\n",
            "-2.3556012153625487 \n",
            " 0.7125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6A2W4CtktCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_MLP = keras.models.Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cthixRBiks8-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_MLP.add(keras.layers.Dense(units=10, activation='relu',input_shape= X_train.shape[1:]))\n",
        "model_MLP.add(keras.layers.Dense(units=5, activation='relu',input_shape= X_train.shape[1:]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_BIspBiks3W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "6c9c9cb8-0129-4b6e-91e6-37604555b41d"
      },
      "source": [
        "model_MLP.add(keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "model_MLP.summary()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5)                 55        \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 6         \n",
            "=================================================================\n",
            "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "Total params: 165\n",
            "Trainable params: 165\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trSqwbETksyj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_MLP.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrENj-xYkstA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bd233081-92e1-46d6-ceda-a16079332fa7"
      },
      "source": [
        "model_MLP.fit(x=X_train_std, y=y_train, validation_split=0.1,epochs=50, batch_size=16)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 377 samples, validate on 42 samples\n",
            "Epoch 1/50\n",
            "377/377 [==============================] - 0s 382us/sample - loss: 0.8437 - acc: 0.2149 - val_loss: 0.7503 - val_acc: 0.4048\n",
            "Epoch 2/50\n",
            "377/377 [==============================] - 0s 111us/sample - loss: 0.6721 - acc: 0.4642 - val_loss: 0.6042 - val_acc: 0.6429\n",
            "Epoch 3/50\n",
            "377/377 [==============================] - 0s 112us/sample - loss: 0.5445 - acc: 0.6578 - val_loss: 0.4886 - val_acc: 0.8095\n",
            "Epoch 4/50\n",
            "377/377 [==============================] - 0s 108us/sample - loss: 0.4367 - acc: 0.6844 - val_loss: 0.3839 - val_acc: 0.8333\n",
            "Epoch 5/50\n",
            "377/377 [==============================] - 0s 108us/sample - loss: 0.3225 - acc: 0.6976 - val_loss: 0.2806 - val_acc: 0.8333\n",
            "Epoch 6/50\n",
            "377/377 [==============================] - 0s 117us/sample - loss: 0.1900 - acc: 0.7003 - val_loss: 0.1660 - val_acc: 0.8333\n",
            "Epoch 7/50\n",
            "377/377 [==============================] - 0s 137us/sample - loss: 0.0218 - acc: 0.7003 - val_loss: 0.0060 - val_acc: 0.8333\n",
            "Epoch 8/50\n",
            "377/377 [==============================] - 0s 117us/sample - loss: -0.2248 - acc: 0.7003 - val_loss: -0.1864 - val_acc: 0.8333\n",
            "Epoch 9/50\n",
            "377/377 [==============================] - 0s 102us/sample - loss: -0.4951 - acc: 0.7029 - val_loss: -0.3589 - val_acc: 0.8333\n",
            "Epoch 10/50\n",
            "377/377 [==============================] - 0s 130us/sample - loss: -0.7615 - acc: 0.7029 - val_loss: -0.5334 - val_acc: 0.8333\n",
            "Epoch 11/50\n",
            "377/377 [==============================] - 0s 127us/sample - loss: -1.0382 - acc: 0.7003 - val_loss: -0.7209 - val_acc: 0.8333\n",
            "Epoch 12/50\n",
            "377/377 [==============================] - 0s 112us/sample - loss: -1.3672 - acc: 0.7003 - val_loss: -0.9232 - val_acc: 0.8333\n",
            "Epoch 13/50\n",
            "377/377 [==============================] - 0s 117us/sample - loss: -1.7343 - acc: 0.7003 - val_loss: -1.1704 - val_acc: 0.8333\n",
            "Epoch 14/50\n",
            "377/377 [==============================] - 0s 108us/sample - loss: -2.1780 - acc: 0.7003 - val_loss: -1.4579 - val_acc: 0.8333\n",
            "Epoch 15/50\n",
            "377/377 [==============================] - 0s 106us/sample - loss: -2.6961 - acc: 0.7003 - val_loss: -1.7974 - val_acc: 0.8333\n",
            "Epoch 16/50\n",
            "377/377 [==============================] - 0s 111us/sample - loss: -3.3034 - acc: 0.7003 - val_loss: -2.2010 - val_acc: 0.8333\n",
            "Epoch 17/50\n",
            "377/377 [==============================] - 0s 127us/sample - loss: -4.0310 - acc: 0.7003 - val_loss: -2.6650 - val_acc: 0.8333\n",
            "Epoch 18/50\n",
            "377/377 [==============================] - 0s 136us/sample - loss: -4.8531 - acc: 0.7003 - val_loss: -3.2308 - val_acc: 0.8333\n",
            "Epoch 19/50\n",
            "377/377 [==============================] - 0s 129us/sample - loss: -5.8386 - acc: 0.7003 - val_loss: -3.8225 - val_acc: 0.8333\n",
            "Epoch 20/50\n",
            "377/377 [==============================] - 0s 110us/sample - loss: -6.8887 - acc: 0.7003 - val_loss: -4.5563 - val_acc: 0.8333\n",
            "Epoch 21/50\n",
            "377/377 [==============================] - 0s 111us/sample - loss: -8.1415 - acc: 0.7029 - val_loss: -5.3512 - val_acc: 0.8333\n",
            "Epoch 22/50\n",
            "377/377 [==============================] - 0s 107us/sample - loss: -9.5356 - acc: 0.7029 - val_loss: -6.2730 - val_acc: 0.8333\n",
            "Epoch 23/50\n",
            "377/377 [==============================] - 0s 111us/sample - loss: -11.1234 - acc: 0.7029 - val_loss: -7.2906 - val_acc: 0.8333\n",
            "Epoch 24/50\n",
            "377/377 [==============================] - 0s 110us/sample - loss: -12.8757 - acc: 0.7029 - val_loss: -8.3925 - val_acc: 0.8333\n",
            "Epoch 25/50\n",
            "377/377 [==============================] - 0s 109us/sample - loss: -14.7742 - acc: 0.7029 - val_loss: -9.6530 - val_acc: 0.8333\n",
            "Epoch 26/50\n",
            "377/377 [==============================] - 0s 121us/sample - loss: -16.8801 - acc: 0.7029 - val_loss: -11.0413 - val_acc: 0.8333\n",
            "Epoch 27/50\n",
            "377/377 [==============================] - 0s 111us/sample - loss: -19.1892 - acc: 0.7029 - val_loss: -12.5683 - val_acc: 0.8333\n",
            "Epoch 28/50\n",
            "377/377 [==============================] - 0s 107us/sample - loss: -21.7214 - acc: 0.7029 - val_loss: -14.1854 - val_acc: 0.8333\n",
            "Epoch 29/50\n",
            "377/377 [==============================] - 0s 117us/sample - loss: -24.4431 - acc: 0.7029 - val_loss: -15.9216 - val_acc: 0.8333\n",
            "Epoch 30/50\n",
            "377/377 [==============================] - 0s 132us/sample - loss: -27.3190 - acc: 0.7029 - val_loss: -17.9105 - val_acc: 0.8333\n",
            "Epoch 31/50\n",
            "377/377 [==============================] - 0s 106us/sample - loss: -30.5713 - acc: 0.7029 - val_loss: -19.9238 - val_acc: 0.8333\n",
            "Epoch 32/50\n",
            "377/377 [==============================] - 0s 109us/sample - loss: -34.0472 - acc: 0.7029 - val_loss: -22.1505 - val_acc: 0.8333\n",
            "Epoch 33/50\n",
            "377/377 [==============================] - 0s 123us/sample - loss: -37.7081 - acc: 0.7029 - val_loss: -24.6337 - val_acc: 0.8333\n",
            "Epoch 34/50\n",
            "377/377 [==============================] - 0s 109us/sample - loss: -41.7290 - acc: 0.7029 - val_loss: -27.1965 - val_acc: 0.8333\n",
            "Epoch 35/50\n",
            "377/377 [==============================] - 0s 115us/sample - loss: -45.8700 - acc: 0.7029 - val_loss: -30.0930 - val_acc: 0.8333\n",
            "Epoch 36/50\n",
            "377/377 [==============================] - 0s 114us/sample - loss: -50.4879 - acc: 0.7029 - val_loss: -32.8318 - val_acc: 0.8333\n",
            "Epoch 37/50\n",
            "377/377 [==============================] - 0s 108us/sample - loss: -54.9409 - acc: 0.7029 - val_loss: -36.0080 - val_acc: 0.8333\n",
            "Epoch 38/50\n",
            "377/377 [==============================] - 0s 113us/sample - loss: -59.9948 - acc: 0.7029 - val_loss: -39.2363 - val_acc: 0.8333\n",
            "Epoch 39/50\n",
            "377/377 [==============================] - 0s 114us/sample - loss: -65.0903 - acc: 0.7029 - val_loss: -42.7165 - val_acc: 0.8333\n",
            "Epoch 40/50\n",
            "377/377 [==============================] - 0s 110us/sample - loss: -70.7285 - acc: 0.7029 - val_loss: -46.2149 - val_acc: 0.8333\n",
            "Epoch 41/50\n",
            "377/377 [==============================] - 0s 112us/sample - loss: -76.5016 - acc: 0.7029 - val_loss: -49.9806 - val_acc: 0.8333\n",
            "Epoch 42/50\n",
            "377/377 [==============================] - 0s 113us/sample - loss: -82.4614 - acc: 0.7029 - val_loss: -54.1302 - val_acc: 0.8333\n",
            "Epoch 43/50\n",
            "377/377 [==============================] - 0s 110us/sample - loss: -88.9576 - acc: 0.7029 - val_loss: -58.1555 - val_acc: 0.8333\n",
            "Epoch 44/50\n",
            "377/377 [==============================] - 0s 116us/sample - loss: -95.4550 - acc: 0.7029 - val_loss: -62.3872 - val_acc: 0.8333\n",
            "Epoch 45/50\n",
            "377/377 [==============================] - 0s 109us/sample - loss: -102.2975 - acc: 0.7029 - val_loss: -66.8497 - val_acc: 0.8333\n",
            "Epoch 46/50\n",
            "377/377 [==============================] - 0s 107us/sample - loss: -109.4971 - acc: 0.7029 - val_loss: -71.6366 - val_acc: 0.8333\n",
            "Epoch 47/50\n",
            "377/377 [==============================] - 0s 119us/sample - loss: -117.0939 - acc: 0.7029 - val_loss: -76.7390 - val_acc: 0.8333\n",
            "Epoch 48/50\n",
            "377/377 [==============================] - 0s 107us/sample - loss: -125.1823 - acc: 0.7029 - val_loss: -81.7261 - val_acc: 0.8333\n",
            "Epoch 49/50\n",
            "377/377 [==============================] - 0s 109us/sample - loss: -133.3306 - acc: 0.7029 - val_loss: -87.0744 - val_acc: 0.8333\n",
            "Epoch 50/50\n",
            "377/377 [==============================] - 0s 105us/sample - loss: -141.8281 - acc: 0.7029 - val_loss: -92.6939 - val_acc: 0.8333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd9aab20e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXNYvsVFl2u-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "efc499f0-583d-4ed5-95cc-8232ec8eda8d"
      },
      "source": [
        "test_loss, test_accuracy = model_MLP.evaluate(x=X_test_std, y=y_test)\n",
        "\n",
        "print(test_loss, '\\n',test_accuracy)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "160/160 [==============================] - 0s 75us/sample - loss: -142.0526 - acc: 0.7125\n",
            "-142.05257110595704 \n",
            " 0.7125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86iX9jeFksny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJwlF7Bqksh7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}