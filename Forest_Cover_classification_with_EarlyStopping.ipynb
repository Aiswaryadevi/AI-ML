{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Forest Cover classification with EarlyStopping.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPxAuWT5PXcjEYw8VsIHHna",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aiswaryadevi/AI-deeplearning/blob/master/Forest_Cover_classification_with_EarlyStopping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cj7aGEUIMyGB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7kKgrzfN1uY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "outputId": "7da78fba-5e00-4f9b-998a-a29ae500c21e"
      },
      "source": [
        "# Load the dataset from sklearn\n",
        "from sklearn.datasets import fetch_covtype\n",
        "# Importing both TensorFlow and its high level API - Keras.\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "# Setting the random seeds for repeatability\n",
        "tf.random.set_random_seed(42)\n",
        "np.random.seed(42)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToiU0aImN5Ag",
        "colab_type": "code",
        "outputId": "13f35df5-9b42-4e43-e9c5-e54c5106c143",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# When return_X_y = True, the load function\n",
        "# return data and target instead of Bunch object.\n",
        "X, y = fetch_covtype(return_X_y=True)\n",
        "print(type(X))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://ndownloader.figshare.com/files/5976039\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_KrGb0oOLDA",
        "colab_type": "code",
        "outputId": "068af560-54f1-4d73-bd06-e22959ef993a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Reduce the number of attributes, consider only first 10 attributes.\n",
        "X_10 = X[:,:10]\n",
        "print(X_10.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(581012, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgQxNIFrOcmu",
        "colab_type": "code",
        "outputId": "bc5ce06c-c165-4636-9e6e-368a5d9a7094",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Split the data into 90% training and 10% testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "# The 10% testing data obtained during this split will be take as our entire database.\n",
        "# This is because the original dataset is too big.\n",
        "X10_train, X10_test, y10_train, y10_test = train_test_split(X_10, y, test_size=0.1,\n",
        " stratify=y, random_state=42)\n",
        "print(X10_test.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(58102, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yge_tuTOhNR",
        "colab_type": "code",
        "outputId": "0e3497e4-a7e5-47d2-f5ed-a225d1c63140",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Handle only the modified 1% dataset. Split that into training and testing.\n",
        "# X and y are updated with the downsized dataset\n",
        "X = X10_test\n",
        "y = y10_test\n",
        "print(set(y))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1, 2, 3, 4, 5, 6, 7}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oAeLUAGOlOM",
        "colab_type": "code",
        "outputId": "945ff756-5a9e-49ef-8ec4-678c4d45e320",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# The label should start from 0, but by default, the labels are from 1 to 7.\n",
        "# Change them to the range 0 to 6 by subtracting 1 from the labels.\n",
        "y = y-1\n",
        "print(set(y))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0, 1, 2, 3, 4, 5, 6}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CojydC1FO7jG",
        "colab_type": "code",
        "outputId": "0d12cfea-0a9c-47af-ee8e-f3d6ff71877e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Split the data into 80% training and 20% testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "# While splitting, make an unbiased splitting\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        " stratify=y, random_state=42)\n",
        "# Feature scaling using Standardization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "# Training the feature scaling parameters\n",
        "sc.fit(X_train)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler(copy=True, with_mean=True, with_std=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOO-I2b_PBGG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "fd917b81-0a98-4733-8dc1-e9fe05bc9eb4"
      },
      "source": [
        "# Applying transformations to both training and testing set\n",
        "X_train_std = sc.transform(X_train)\n",
        "X_test_std = sc.transform(X_test)\n",
        "# Create neural network using keras API\n",
        "# Sequential() does linear stacking of layers\n",
        "model_DNN = keras.models.Sequential()\n",
        "# Hidden layer definitions\n",
        "model_DNN.add(keras.layers.Dense(units=25, activation='relu', input_shape=\n",
        "X_train.shape[1:]))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDFT7jfjPEuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Batch Normalization is applied after the first layer transformation in this example.\n",
        "model_DNN.add(keras.layers.BatchNormalization())\n",
        "model_DNN.add(keras.layers.Dense(units=20, activation='relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP90IF2xPLC0",
        "colab_type": "code",
        "outputId": "3d38ba76-44f4-4bd8-9acb-1588be6e681b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "model_DNN.add(keras.layers.Dense(units= 15, activation='relu'))\n",
        "model_DNN.add(keras.layers.Dense(units=10, activation='relu'))\n",
        "# Output layer definitions\n",
        "model_DNN.add(keras.layers.Dense(units=7, activation='sigmoid'))\n",
        "# Print the summary of network architecture\n",
        "model_DNN.summary()\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 25)                275       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 25)                100       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20)                520       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 15)                315       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                160       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 7)                 77        \n",
            "=================================================================\n",
            "Total params: 1,447\n",
            "Trainable params: 1,397\n",
            "Non-trainable params: 50\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buUPExhKPOtU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss, optimizer and metrics are three important configurations.\n",
        "model_DNN.compile(loss='sparse_categorical_crossentropy',\n",
        " optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYTyxP3dPRsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cb_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        " patience=10, restore_best_weights=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygkTf0NjPUrR",
        "colab_type": "code",
        "outputId": "5ca35653-9f80-46fc-923c-eb0d3aa246ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_DNN.fit(x=X_train_std, y=y_train, validation_split=0.1,\n",
        " epochs=100, batch_size=16, callbacks=[cb_early_stopping])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 41832 samples, validate on 4649 samples\n",
            "Epoch 1/100\n",
            "41832/41832 [==============================] - 6s 132us/sample - loss: 0.8439 - acc: 0.6308 - val_loss: 0.6795 - val_acc: 0.7105\n",
            "Epoch 2/100\n",
            "41832/41832 [==============================] - 5s 121us/sample - loss: 0.7300 - acc: 0.6866 - val_loss: 0.6704 - val_acc: 0.7051\n",
            "Epoch 3/100\n",
            "41832/41832 [==============================] - 5s 123us/sample - loss: 0.7106 - acc: 0.6905 - val_loss: 0.6375 - val_acc: 0.7240\n",
            "Epoch 4/100\n",
            "41832/41832 [==============================] - 5s 121us/sample - loss: 0.6964 - acc: 0.6980 - val_loss: 0.6354 - val_acc: 0.7186\n",
            "Epoch 5/100\n",
            "41832/41832 [==============================] - 5s 122us/sample - loss: 0.6866 - acc: 0.7003 - val_loss: 0.6244 - val_acc: 0.7275\n",
            "Epoch 6/100\n",
            "41832/41832 [==============================] - 5s 118us/sample - loss: 0.6788 - acc: 0.7027 - val_loss: 0.6224 - val_acc: 0.7296\n",
            "Epoch 7/100\n",
            "41832/41832 [==============================] - 5s 120us/sample - loss: 0.6750 - acc: 0.7035 - val_loss: 0.6104 - val_acc: 0.7316\n",
            "Epoch 8/100\n",
            "41832/41832 [==============================] - 5s 119us/sample - loss: 0.6658 - acc: 0.7089 - val_loss: 0.6068 - val_acc: 0.7371\n",
            "Epoch 9/100\n",
            "41832/41832 [==============================] - 5s 118us/sample - loss: 0.6610 - acc: 0.7113 - val_loss: 0.6062 - val_acc: 0.7311\n",
            "Epoch 10/100\n",
            "41832/41832 [==============================] - 5s 119us/sample - loss: 0.6610 - acc: 0.7108 - val_loss: 0.6044 - val_acc: 0.7356\n",
            "Epoch 11/100\n",
            "41832/41832 [==============================] - 5s 118us/sample - loss: 0.6587 - acc: 0.7114 - val_loss: 0.6048 - val_acc: 0.7324\n",
            "Epoch 12/100\n",
            "41832/41832 [==============================] - 5s 122us/sample - loss: 0.6535 - acc: 0.7131 - val_loss: 0.5940 - val_acc: 0.7391\n",
            "Epoch 13/100\n",
            "41832/41832 [==============================] - 5s 128us/sample - loss: 0.6538 - acc: 0.7142 - val_loss: 0.6001 - val_acc: 0.7406\n",
            "Epoch 14/100\n",
            "41832/41832 [==============================] - 5s 128us/sample - loss: 0.6480 - acc: 0.7155 - val_loss: 0.5973 - val_acc: 0.7412\n",
            "Epoch 15/100\n",
            "41832/41832 [==============================] - 5s 127us/sample - loss: 0.6446 - acc: 0.7181 - val_loss: 0.5983 - val_acc: 0.7354\n",
            "Epoch 16/100\n",
            "41832/41832 [==============================] - 5s 120us/sample - loss: 0.6462 - acc: 0.7178 - val_loss: 0.5919 - val_acc: 0.7380\n",
            "Epoch 17/100\n",
            "41832/41832 [==============================] - 5s 125us/sample - loss: 0.6446 - acc: 0.7179 - val_loss: 0.5872 - val_acc: 0.7393\n",
            "Epoch 18/100\n",
            "41832/41832 [==============================] - 5s 124us/sample - loss: 0.6441 - acc: 0.7202 - val_loss: 0.5904 - val_acc: 0.7477\n",
            "Epoch 19/100\n",
            "41832/41832 [==============================] - 5s 122us/sample - loss: 0.6394 - acc: 0.7213 - val_loss: 0.5819 - val_acc: 0.7451\n",
            "Epoch 20/100\n",
            "41832/41832 [==============================] - 5s 123us/sample - loss: 0.6351 - acc: 0.7217 - val_loss: 0.5786 - val_acc: 0.7436\n",
            "Epoch 21/100\n",
            "41832/41832 [==============================] - 5s 123us/sample - loss: 0.6373 - acc: 0.7213 - val_loss: 0.5874 - val_acc: 0.7421\n",
            "Epoch 22/100\n",
            "41832/41832 [==============================] - 5s 123us/sample - loss: 0.6343 - acc: 0.7211 - val_loss: 0.5730 - val_acc: 0.7479\n",
            "Epoch 23/100\n",
            "41832/41832 [==============================] - 5s 123us/sample - loss: 0.6350 - acc: 0.7227 - val_loss: 0.5802 - val_acc: 0.7505\n",
            "Epoch 24/100\n",
            "41832/41832 [==============================] - 5s 122us/sample - loss: 0.6345 - acc: 0.7243 - val_loss: 0.5827 - val_acc: 0.7462\n",
            "Epoch 25/100\n",
            "41832/41832 [==============================] - 5s 120us/sample - loss: 0.6301 - acc: 0.7255 - val_loss: 0.5766 - val_acc: 0.7483\n",
            "Epoch 26/100\n",
            "41832/41832 [==============================] - 5s 121us/sample - loss: 0.6284 - acc: 0.7256 - val_loss: 0.5828 - val_acc: 0.7458\n",
            "Epoch 27/100\n",
            "41832/41832 [==============================] - 5s 121us/sample - loss: 0.6295 - acc: 0.7259 - val_loss: 0.5670 - val_acc: 0.7509\n",
            "Epoch 28/100\n",
            "41832/41832 [==============================] - 5s 118us/sample - loss: 0.6322 - acc: 0.7244 - val_loss: 0.5806 - val_acc: 0.7501\n",
            "Epoch 29/100\n",
            "41832/41832 [==============================] - 5s 124us/sample - loss: 0.6267 - acc: 0.7271 - val_loss: 0.5753 - val_acc: 0.7524\n",
            "Epoch 30/100\n",
            "41832/41832 [==============================] - 5s 122us/sample - loss: 0.6247 - acc: 0.7273 - val_loss: 0.5765 - val_acc: 0.7529\n",
            "Epoch 31/100\n",
            "41832/41832 [==============================] - 5s 126us/sample - loss: 0.6281 - acc: 0.7256 - val_loss: 0.5769 - val_acc: 0.7531\n",
            "Epoch 32/100\n",
            "41832/41832 [==============================] - 6s 149us/sample - loss: 0.6273 - acc: 0.7275 - val_loss: 0.5715 - val_acc: 0.7494\n",
            "Epoch 33/100\n",
            "41832/41832 [==============================] - 5s 122us/sample - loss: 0.6219 - acc: 0.7275 - val_loss: 0.5809 - val_acc: 0.7490\n",
            "Epoch 34/100\n",
            "41832/41832 [==============================] - 5s 123us/sample - loss: 0.6246 - acc: 0.7288 - val_loss: 0.5662 - val_acc: 0.7531\n",
            "Epoch 35/100\n",
            "41832/41832 [==============================] - 5s 123us/sample - loss: 0.6239 - acc: 0.7291 - val_loss: 0.5680 - val_acc: 0.7522\n",
            "Epoch 36/100\n",
            "41832/41832 [==============================] - 5s 120us/sample - loss: 0.6237 - acc: 0.7297 - val_loss: 0.5692 - val_acc: 0.7524\n",
            "Epoch 37/100\n",
            "41832/41832 [==============================] - 5s 122us/sample - loss: 0.6250 - acc: 0.7274 - val_loss: 0.5736 - val_acc: 0.7541\n",
            "Epoch 38/100\n",
            "41832/41832 [==============================] - 5s 122us/sample - loss: 0.6239 - acc: 0.7274 - val_loss: 0.5673 - val_acc: 0.7458\n",
            "Epoch 39/100\n",
            "41832/41832 [==============================] - 5s 121us/sample - loss: 0.6213 - acc: 0.7279 - val_loss: 0.5708 - val_acc: 0.7477\n",
            "Epoch 40/100\n",
            "41832/41832 [==============================] - 5s 125us/sample - loss: 0.6243 - acc: 0.7263 - val_loss: 0.5690 - val_acc: 0.7513\n",
            "Epoch 41/100\n",
            "41832/41832 [==============================] - 5s 125us/sample - loss: 0.6221 - acc: 0.7283 - val_loss: 0.5634 - val_acc: 0.7541\n",
            "Epoch 42/100\n",
            "41832/41832 [==============================] - 5s 124us/sample - loss: 0.6206 - acc: 0.7285 - val_loss: 0.5753 - val_acc: 0.7475\n",
            "Epoch 43/100\n",
            "41832/41832 [==============================] - 5s 124us/sample - loss: 0.6188 - acc: 0.7288 - val_loss: 0.5684 - val_acc: 0.7505\n",
            "Epoch 44/100\n",
            "41832/41832 [==============================] - 5s 124us/sample - loss: 0.6170 - acc: 0.7305 - val_loss: 0.5737 - val_acc: 0.7509\n",
            "Epoch 45/100\n",
            "41832/41832 [==============================] - 5s 122us/sample - loss: 0.6195 - acc: 0.7297 - val_loss: 0.5686 - val_acc: 0.7533\n",
            "Epoch 46/100\n",
            "41832/41832 [==============================] - 5s 124us/sample - loss: 0.6189 - acc: 0.7292 - val_loss: 0.5631 - val_acc: 0.7496\n",
            "Epoch 47/100\n",
            "41832/41832 [==============================] - 5s 122us/sample - loss: 0.6191 - acc: 0.7306 - val_loss: 0.5665 - val_acc: 0.7541\n",
            "Epoch 48/100\n",
            "41832/41832 [==============================] - 5s 119us/sample - loss: 0.6181 - acc: 0.7299 - val_loss: 0.5649 - val_acc: 0.7584\n",
            "Epoch 49/100\n",
            "41832/41832 [==============================] - 5s 121us/sample - loss: 0.6164 - acc: 0.7306 - val_loss: 0.5629 - val_acc: 0.7546\n",
            "Epoch 50/100\n",
            "41832/41832 [==============================] - 5s 130us/sample - loss: 0.6175 - acc: 0.7307 - val_loss: 0.5722 - val_acc: 0.7481\n",
            "Epoch 51/100\n",
            "41832/41832 [==============================] - 5s 120us/sample - loss: 0.6161 - acc: 0.7305 - val_loss: 0.5730 - val_acc: 0.7494\n",
            "Epoch 52/100\n",
            "41832/41832 [==============================] - 5s 125us/sample - loss: 0.6173 - acc: 0.7294 - val_loss: 0.5646 - val_acc: 0.7529\n",
            "Epoch 53/100\n",
            "41832/41832 [==============================] - 5s 122us/sample - loss: 0.6171 - acc: 0.7309 - val_loss: 0.5601 - val_acc: 0.7516\n",
            "Epoch 54/100\n",
            "41832/41832 [==============================] - 5s 123us/sample - loss: 0.6152 - acc: 0.7310 - val_loss: 0.5601 - val_acc: 0.7524\n",
            "Epoch 55/100\n",
            "41832/41832 [==============================] - 5s 125us/sample - loss: 0.6140 - acc: 0.7321 - val_loss: 0.5650 - val_acc: 0.7544\n",
            "Epoch 56/100\n",
            "41832/41832 [==============================] - 5s 125us/sample - loss: 0.6172 - acc: 0.7289 - val_loss: 0.5596 - val_acc: 0.7567\n",
            "Epoch 57/100\n",
            "41832/41832 [==============================] - 5s 124us/sample - loss: 0.6159 - acc: 0.7311 - val_loss: 0.5621 - val_acc: 0.7503\n",
            "Epoch 58/100\n",
            "41832/41832 [==============================] - 5s 122us/sample - loss: 0.6128 - acc: 0.7317 - val_loss: 0.5641 - val_acc: 0.7481\n",
            "Epoch 59/100\n",
            "41832/41832 [==============================] - 5s 129us/sample - loss: 0.6122 - acc: 0.7336 - val_loss: 0.5613 - val_acc: 0.7522\n",
            "Epoch 60/100\n",
            "41832/41832 [==============================] - 5s 122us/sample - loss: 0.6121 - acc: 0.7333 - val_loss: 0.5530 - val_acc: 0.7518\n",
            "Epoch 61/100\n",
            "41832/41832 [==============================] - 5s 122us/sample - loss: 0.6180 - acc: 0.7313 - val_loss: 0.5633 - val_acc: 0.7455\n",
            "Epoch 62/100\n",
            "41832/41832 [==============================] - 5s 120us/sample - loss: 0.6138 - acc: 0.7329 - val_loss: 0.5598 - val_acc: 0.7541\n",
            "Epoch 63/100\n",
            "41832/41832 [==============================] - 5s 123us/sample - loss: 0.6151 - acc: 0.7314 - val_loss: 0.5618 - val_acc: 0.7498\n",
            "Epoch 64/100\n",
            "41832/41832 [==============================] - 6s 138us/sample - loss: 0.6140 - acc: 0.7325 - val_loss: 0.5644 - val_acc: 0.7464\n",
            "Epoch 65/100\n",
            "41832/41832 [==============================] - 6s 134us/sample - loss: 0.6124 - acc: 0.7312 - val_loss: 0.5758 - val_acc: 0.7501\n",
            "Epoch 66/100\n",
            "41832/41832 [==============================] - 6s 133us/sample - loss: 0.6119 - acc: 0.7331 - val_loss: 0.5585 - val_acc: 0.7559\n",
            "Epoch 67/100\n",
            "41832/41832 [==============================] - 5s 124us/sample - loss: 0.6132 - acc: 0.7305 - val_loss: 0.5576 - val_acc: 0.7548\n",
            "Epoch 68/100\n",
            "41832/41832 [==============================] - 5s 121us/sample - loss: 0.6114 - acc: 0.7319 - val_loss: 0.5614 - val_acc: 0.7485\n",
            "Epoch 69/100\n",
            "41832/41832 [==============================] - 5s 122us/sample - loss: 0.6099 - acc: 0.7338 - val_loss: 0.5588 - val_acc: 0.7513\n",
            "Epoch 70/100\n",
            "41832/41832 [==============================] - 5s 124us/sample - loss: 0.6083 - acc: 0.7360 - val_loss: 0.5635 - val_acc: 0.7462\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f09f020c358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkCYC12dPXOx",
        "colab_type": "code",
        "outputId": "7b93e727-9765-415e-f6c8-8855ff395e9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_loss, test_accuracy = model_DNN.evaluate(x=X_test_std, y=y_test)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11621/11621 [==============================] - 0s 25us/sample - loss: 0.5781 - acc: 0.7468\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuZ9MrRHPZ5s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "033f9f7b-8e17-4037-fabf-f89941f1defa"
      },
      "source": [
        "print(test_loss, test_accuracy)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.578132525018443 0.7468376\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTCu_jKGPcwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}